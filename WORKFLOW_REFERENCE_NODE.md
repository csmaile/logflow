# LogFlow å·¥ä½œæµå…³è”èŠ‚ç‚¹æŒ‡å—

## ğŸ¯ æ¦‚è¿°

**å…³è”èŠ‚ç‚¹ï¼ˆReferenceNodeï¼‰**æ˜¯LogFlowå·¥ä½œæµç³»ç»Ÿçš„é«˜çº§åŠŸèƒ½ï¼Œå…è®¸ä¸€ä¸ªå·¥ä½œæµå¼•ç”¨å’Œæ‰§è¡Œå…¶ä»–å·²æ³¨å†Œçš„å·¥ä½œæµï¼Œå®ç°å·¥ä½œæµçš„**ç»„åˆ**ã€**å¤ç”¨**å’Œ**ç¼–æ’**ã€‚è¿™æ˜¯æ„å»ºå¤æ‚ä¸šåŠ¡æµç¨‹çš„æ ¸å¿ƒèƒ½åŠ›ã€‚

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### å…³é”®ç»„ä»¶

1. **ReferenceNode** - å…³è”èŠ‚ç‚¹å®ç°
2. **WorkflowRegistry** - å·¥ä½œæµæ³¨å†Œä¸­å¿ƒ  
3. **ExecutionMode** - å¤šç§æ‰§è¡Œæ¨¡å¼
4. **æ•°æ®æ˜ å°„æœºåˆ¶** - å·¥ä½œæµé—´æ•°æ®ä¼ é€’
5. **æ¡ä»¶è¯„ä¼°å¼•æ“** - æ™ºèƒ½æ‰§è¡Œæ§åˆ¶

### ç³»ç»Ÿç‰¹æ€§

```mermaid
graph TD
    A[ä¸»å·¥ä½œæµ] --> B[å…³è”èŠ‚ç‚¹]
    B --> C[å·¥ä½œæµæ³¨å†Œä¸­å¿ƒ]
    C --> D[ç›®æ ‡å·¥ä½œæµ1]
    C --> E[ç›®æ ‡å·¥ä½œæµ2]
    C --> F[ç›®æ ‡å·¥ä½œæµ3]
    
    B --> G[æ‰§è¡Œæ¨¡å¼é€‰æ‹©]
    G --> H[åŒæ­¥æ‰§è¡Œ]
    G --> I[å¼‚æ­¥æ‰§è¡Œ]
    G --> J[æ¡ä»¶æ‰§è¡Œ]
    G --> K[å¾ªç¯æ‰§è¡Œ]
    G --> L[å¹¶è¡Œæ‰§è¡Œ]
    
    B --> M[æ•°æ®æ˜ å°„]
    M --> N[è¾“å…¥æ˜ å°„]
    M --> O[è¾“å‡ºæ˜ å°„]
    M --> P[å›ºå®šå‚æ•°]
```

## ğŸš€ æ‰§è¡Œæ¨¡å¼è¯¦è§£

### 1. åŒæ­¥æ‰§è¡Œæ¨¡å¼ (SYNC)

**æœ€åŸºç¡€çš„æ‰§è¡Œæ¨¡å¼**ï¼Œå…³è”èŠ‚ç‚¹ç­‰å¾…è¢«å¼•ç”¨å·¥ä½œæµå®Œå…¨æ‰§è¡Œå®Œæˆåå†ç»§ç»­ã€‚

```yaml
nodes:
  - id: ref-sync
    type: reference
    name: åŒæ­¥æ•°æ®å¤„ç†
    config:
      executionMode: SYNC
      workflowId: data-processing-workflow
      inputMappings:
        source_data: input_data
        config_params: processing_config
      outputMappings:
        processed_result: main_result
        statistics: processing_stats
```

**ç‰¹ç‚¹**ï¼š
- âœ… ç®€å•å¯é ï¼Œç»“æœç¡®å®š
- âœ… ä¾¿äºè°ƒè¯•å’Œé”™è¯¯å¤„ç†
- âš ï¸ å¯èƒ½é€ æˆé•¿æ—¶é—´é˜»å¡
- ğŸ“Š é€‚ç”¨äºæ•°æ®ä¾èµ–æ€§å¼ºçš„åœºæ™¯

### 2. å¼‚æ­¥æ‰§è¡Œæ¨¡å¼ (ASYNC)

**éé˜»å¡æ‰§è¡Œ**ï¼Œå¯åŠ¨å­å·¥ä½œæµåå¯é€‰æ‹©ç­‰å¾…ç»“æœæˆ–ç»§ç»­æ‰§è¡Œã€‚

```yaml
nodes:
  - id: ref-async
    type: reference
    name: å¼‚æ­¥æŠ¥å‘Šç”Ÿæˆ
    config:
      executionMode: ASYNC
      workflowId: report-generator
      waitForResult: false
      timeoutMs: 30000
      inputMappings:
        report_data: analysis_result
```

**ç‰¹ç‚¹**ï¼š
- âš¡ é«˜å¹¶å‘ï¼Œæ€§èƒ½ä¼˜å¼‚
- ğŸ”„ æ”¯æŒåå°é•¿æ—¶é—´ä»»åŠ¡
- âš ï¸ éœ€è¦å¤„ç†å¼‚æ­¥ç»“æœç®¡ç†
- ğŸ“Š é€‚ç”¨äºç‹¬ç«‹çš„åå°ä»»åŠ¡

### 3. æ¡ä»¶æ‰§è¡Œæ¨¡å¼ (CONDITIONAL)

**åŸºäºæ¡ä»¶çš„æ™ºèƒ½æ‰§è¡Œ**ï¼Œåªæœ‰æ»¡è¶³ç‰¹å®šæ¡ä»¶æ—¶æ‰æ‰§è¡Œå­å·¥ä½œæµã€‚

```yaml
nodes:
  - id: ref-conditional
    type: reference
    name: æ¡ä»¶æ•°æ®æ¸…ç†
    config:
      executionMode: CONDITIONAL
      condition: "${error_count} > 0"
      workflowId: error-cleanup-workflow
      inputMappings:
        error_data: detected_errors
```

**æ¡ä»¶è¡¨è¾¾å¼è¯­æ³•**ï¼š
```javascript
// æ•°å€¼æ¯”è¾ƒ
"${count} > 100"
"${ratio} >= 0.8"
"${temperature} < 50"

// å­—ç¬¦ä¸²æ¯”è¾ƒ  
"${status} == 'success'"
"${environment} != 'production'"

// å¸ƒå°”å€¼æ£€æŸ¥
"${enabled} == true"
"${has_errors} == false"

// å­˜åœ¨æ€§æ£€æŸ¥
"${result_data}"
```

**ç‰¹ç‚¹**ï¼š
- ğŸ¯ æ™ºèƒ½å†³ç­–ï¼ŒèŠ‚çœèµ„æº
- ğŸ§  æ”¯æŒå¤æ‚ä¸šåŠ¡é€»è¾‘
- âš¡ é¿å…ä¸å¿…è¦çš„æ‰§è¡Œ
- ğŸ“Š é€‚ç”¨äºåˆ†æ”¯å¤„ç†åœºæ™¯

### 4. å¾ªç¯æ‰§è¡Œæ¨¡å¼ (LOOP)

**æ‰¹é‡æ•°æ®å¤„ç†**ï¼Œå¯¹æ•°æ®é›†åˆä¸­çš„æ¯ä¸ªå…ƒç´ æ‰§è¡Œç›¸åŒçš„å­å·¥ä½œæµã€‚

```yaml
nodes:
  - id: ref-loop
    type: reference
    name: æ‰¹é‡æ–‡ä»¶å¤„ç†
    config:
      executionMode: LOOP
      workflowId: file-processor
      loopDataKey: file_list
      maxIterations: 100
      inputMappings:
        loopItem: current_file
        loopIndex: file_index
```

**å¾ªç¯ç±»å‹**ï¼š

1. **æ•°æ®åˆ—è¡¨å¾ªç¯**ï¼š
```java
// éå†æ–‡ä»¶åˆ—è¡¨
List<String> fileList = Arrays.asList("file1.txt", "file2.txt", "file3.txt");
context.setData("file_list", fileList);
```

2. **æ¡ä»¶å¾ªç¯**ï¼š
```yaml
config:
  loopCondition: "${processed_count} < ${total_count}"
  maxIterations: 1000
```

**ç‰¹ç‚¹**ï¼š
- ğŸ”„ è‡ªåŠ¨æ‰¹é‡å¤„ç†
- ğŸ“Š æ”¯æŒè¿›åº¦è·Ÿè¸ª
- âš ï¸ éœ€è¦é˜²æ­¢æ— é™å¾ªç¯
- ğŸ“Š é€‚ç”¨äºETLå’Œæ‰¹å¤„ç†åœºæ™¯

### 5. å¹¶è¡Œæ‰§è¡Œæ¨¡å¼ (PARALLEL)

**åŒæ—¶æ‰§è¡Œå¤šä¸ªå·¥ä½œæµ**ï¼Œæ˜¾è‘—æå‡å¤„ç†æ•ˆç‡ã€‚

```yaml
nodes:
  - id: ref-parallel
    type: reference
    name: å¹¶è¡Œæ•°æ®åˆ†æ
    config:
      executionMode: PARALLEL
      workflowIds:
        - statistical-analysis
        - data-validation
        - quality-check
      parallelTimeoutMs: 60000
      inputMappings:
        analysis_data: input_dataset
```

**ç‰¹ç‚¹**ï¼š
- âš¡ æé«˜çš„å¤„ç†æ•ˆç‡
- ğŸš€ å……åˆ†åˆ©ç”¨ç³»ç»Ÿèµ„æº
- âš ï¸ éœ€è¦ç®¡ç†å¹¶å‘å¤æ‚æ€§
- ğŸ“Š é€‚ç”¨äºç‹¬ç«‹çš„å¹¶è¡Œä»»åŠ¡

## ğŸ—ƒï¸ å·¥ä½œæµæ³¨å†Œä¸­å¿ƒ

### åŸºæœ¬æ“ä½œ

```java
WorkflowRegistry registry = WorkflowRegistry.getInstance();

// æ³¨å†Œå·¥ä½œæµ
registry.registerWorkflow(workflow, WorkflowStatus.ACTIVE, "æè¿°", "1.0.0");

// è·å–å·¥ä½œæµ
Workflow targetWorkflow = registry.getWorkflow("workflow-id");

// æ£€æŸ¥å­˜åœ¨æ€§
boolean exists = registry.hasWorkflow("workflow-id");

// è·å–æ‰€æœ‰æ´»è·ƒå·¥ä½œæµ
Set<String> activeIds = registry.getActiveWorkflowIds();
```

### ä¾èµ–å…³ç³»ç®¡ç†

```java
// æ·»åŠ ä¾èµ–
registry.addWorkflowDependency("main-workflow", "dependency-workflow");

// æ£€æŸ¥å¾ªç¯ä¾èµ–
boolean hasCircular = registry.hasCircularDependency("workflow-id");

// è·å–ä¾èµ–æ­¤å·¥ä½œæµçš„å…¶ä»–å·¥ä½œæµ
Set<String> dependents = registry.getWorkflowDependents("workflow-id");
```

### æœç´¢å’Œç»Ÿè®¡

```java
// æœç´¢å·¥ä½œæµ
List<WorkflowInfo> results = registry.searchWorkflows("æ•°æ®å¤„ç†");

// è·å–ç»Ÿè®¡ä¿¡æ¯
RegistryStatistics stats = registry.getStatistics();
System.out.println("æ€»å·¥ä½œæµ: " + stats.getTotalWorkflows());
System.out.println("æ´»è·ƒå·¥ä½œæµ: " + stats.getStatusCounts().get(WorkflowStatus.ACTIVE));
```

## ğŸ“Š æ•°æ®æ˜ å°„æœºåˆ¶

### è¾“å…¥æ˜ å°„ (inputMappings)

å°†ä¸»å·¥ä½œæµçš„æ•°æ®æ˜ å°„åˆ°å­å·¥ä½œæµçš„è¾“å…¥å‚æ•°ï¼š

```yaml
inputMappings:
  main_data: sub_input          # ä¸»å·¥ä½œæµçš„main_data -> å­å·¥ä½œæµçš„sub_input
  config_params: sub_config     # ä¸»å·¥ä½œæµçš„config_params -> å­å·¥ä½œæµçš„sub_config
  user_info: processing_context # ä¸»å·¥ä½œæµçš„user_info -> å­å·¥ä½œæµçš„processing_context
```

### è¾“å‡ºæ˜ å°„ (outputMappings)

å°†å­å·¥ä½œæµçš„è¾“å‡ºç»“æœæ˜ å°„å›ä¸»å·¥ä½œæµï¼š

```yaml
outputMappings:
  sub_result: main_result       # å­å·¥ä½œæµçš„sub_result -> ä¸»å·¥ä½œæµçš„main_result
  statistics: execution_stats   # å­å·¥ä½œæµçš„statistics -> ä¸»å·¥ä½œæµçš„execution_stats
  logs: processing_logs        # å­å·¥ä½œæµçš„logs -> ä¸»å·¥ä½œæµçš„processing_logs
```

### å›ºå®šå‚æ•° (fixedParameters)

ä¸ºå­å·¥ä½œæµæä¾›å›ºå®šçš„é…ç½®å‚æ•°ï¼š

```yaml
fixedParameters:
  timeout: 30000
  retry_count: 3
  environment: "production"
  debug_mode: false
```

### è‡ªåŠ¨æ³¨å…¥å‚æ•°

ç³»ç»Ÿè‡ªåŠ¨ä¸ºå­å·¥ä½œæµæ³¨å…¥å…ƒæ•°æ®ï¼š

```java
// è‡ªåŠ¨æ³¨å…¥çš„å‚æ•°
_sourceWorkflowId: "main-workflow"     // æ¥æºå·¥ä½œæµID
_sourceExecutionId: "exec-12345"       // æ¥æºæ‰§è¡ŒID  
_referenceNodeId: "ref-node-01"        // å…³è”èŠ‚ç‚¹ID
```

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

### åŸºç¡€ç”¨æ³•

```java
// 1. åˆ›å»ºå’Œæ³¨å†Œç›®æ ‡å·¥ä½œæµ
Workflow targetWorkflow = WorkflowBuilder.create("data-processor", "æ•°æ®å¤„ç†")
    .addInputNode("input", "æ•°æ®è¾“å…¥")
    .addScriptNode("process", "æ•°æ®å¤„ç†")
    .addOutputNode("output", "ç»“æœè¾“å‡º")
    .connect("input", "process")
    .connect("process", "output")
    .build();

WorkflowRegistry.getInstance().registerWorkflow(targetWorkflow);

// 2. åˆ›å»ºåŒ…å«å…³è”èŠ‚ç‚¹çš„ä¸»å·¥ä½œæµ
Workflow mainWorkflow = WorkflowBuilder.create("main", "ä¸»å·¥ä½œæµ")
    .addInputNode("input", "ä¸»è¾“å…¥")
    .addReferenceNode("ref", "å…³è”å¤„ç†")
    .withConfig(Map.of(
        "executionMode", "SYNC",
        "workflowId", "data-processor",
        "inputMappings", Map.of("input_data", "input_data"),
        "outputMappings", Map.of("processed_data", "result_data")
    ))
    .addOutputNode("output", "ä¸»è¾“å‡º")
    .connect("input", "ref")
    .connect("ref", "output")
    .build();

// 3. æ‰§è¡Œä¸»å·¥ä½œæµ
WorkflowEngine engine = new WorkflowEngine();
WorkflowExecutionResult result = engine.execute(mainWorkflow, inputData);
```

### é«˜çº§é…ç½®

```yaml
# å®Œæ•´çš„å…³è”èŠ‚ç‚¹é…ç½®ç¤ºä¾‹
nodes:
  - id: advanced-reference
    type: reference
    name: é«˜çº§å…³è”èŠ‚ç‚¹
    config:
      # æ‰§è¡Œæ¨¡å¼
      executionMode: CONDITIONAL
      
      # æ¡ä»¶è®¾ç½®
      condition: "${validation_passed} == true && ${error_count} < 5"
      
      # ç›®æ ‡å·¥ä½œæµ
      workflowId: advanced-data-processor
      
      # æ•°æ®æ˜ å°„
      inputMappings:
        source_data: processing_input
        config_settings: processor_config
        metadata: execution_metadata
      
      outputMappings:
        processed_result: main_result
        processing_stats: execution_statistics
        error_log: processing_errors
      
      # å›ºå®šå‚æ•°
      fixedParameters:
        processor_version: "2.1.0"
        max_memory: "2GB"
        timeout_seconds: 300
        retry_enabled: true
      
      # å¼‚æ­¥è®¾ç½®ï¼ˆå¦‚æœæ˜¯å¼‚æ­¥æ¨¡å¼ï¼‰
      waitForResult: true
      timeoutMs: 60000
      
      # å¾ªç¯è®¾ç½®ï¼ˆå¦‚æœæ˜¯å¾ªç¯æ¨¡å¼ï¼‰
      loopDataKey: batch_items
      loopCondition: "${batch_index} < ${total_batches}"
      maxIterations: 1000
      
      # å¹¶è¡Œè®¾ç½®ï¼ˆå¦‚æœæ˜¯å¹¶è¡Œæ¨¡å¼ï¼‰
      workflowIds:
        - data-validator
        - quality-checker
        - statistics-generator
      parallelTimeoutMs: 120000
```

## ğŸ”§ æœ€ä½³å®è·µ

### 1. å·¥ä½œæµè®¾è®¡åŸåˆ™

**å•ä¸€èŒè´£**ï¼š
```java
// âœ… å¥½çš„è®¾è®¡ - æ¯ä¸ªå·¥ä½œæµä¸“æ³¨ä¸€ä¸ªåŠŸèƒ½
register("data-extractor", extractorWorkflow);    // ä¸“æ³¨æ•°æ®æå–
register("data-transformer", transformerWorkflow); // ä¸“æ³¨æ•°æ®è½¬æ¢  
register("data-loader", loaderWorkflow);           // ä¸“æ³¨æ•°æ®åŠ è½½

// âŒ ä¸å¥½çš„è®¾è®¡ - ä¸€ä¸ªå·¥ä½œæµåšæ‰€æœ‰äº‹æƒ…
register("data-etl-everything", massiveWorkflow);
```

**å¯å¤ç”¨æ€§**ï¼š
```java
// âœ… è®¾è®¡å¯å¤ç”¨çš„é€šç”¨å·¥ä½œæµ
register("email-sender", emailWorkflow);      // é€šç”¨é‚®ä»¶å‘é€
register("file-archiver", archiveWorkflow);   // é€šç”¨æ–‡ä»¶å½’æ¡£
register("audit-logger", auditWorkflow);      // é€šç”¨å®¡è®¡æ—¥å¿—

// åœ¨å¤šä¸ªåœ°æ–¹å¤ç”¨
mainWorkflow.addReferenceNode("send-email", "å‘é€é€šçŸ¥")
    .withConfig(Map.of("workflowId", "email-sender"));
```

### 2. é”™è¯¯å¤„ç†ç­–ç•¥

**ä¼˜é›…é™çº§**ï¼š
```yaml
# ä¸»å¤„ç†æµç¨‹
- id: primary-processor
  type: reference
  config:
    executionMode: SYNC
    workflowId: primary-data-processor

# å¤‡ç”¨å¤„ç†æµç¨‹  
- id: fallback-processor
  type: reference
  config:
    executionMode: CONDITIONAL
    condition: "${primary_failed} == true"
    workflowId: fallback-data-processor
```

**é‡è¯•æœºåˆ¶**ï¼š
```java
// åœ¨å­å·¥ä½œæµä¸­å®ç°é‡è¯•é€»è¾‘
Workflow resilientWorkflow = WorkflowBuilder.create("resilient-processor", "å®¹é”™å¤„ç†")
    .addScriptNode("retry-logic", "é‡è¯•æ§åˆ¶")
    .withScript("""
        var maxRetries = context.getData('max_retries') || 3;
        var currentTry = context.getData('current_try') || 0;
        
        if (currentTry < maxRetries) {
            context.setData('should_retry', true);
            context.setData('current_try', currentTry + 1);
        } else {
            context.setData('should_retry', false);
            context.setData('max_retries_reached', true);
        }
    """)
    .build();
```

### 3. æ€§èƒ½ä¼˜åŒ–

**å¹¶è¡Œå¤„ç†**ï¼š
```yaml
# å°†ç‹¬ç«‹ä»»åŠ¡å¹¶è¡ŒåŒ–
- id: parallel-analysis
  type: reference
  config:
    executionMode: PARALLEL
    workflowIds:
      - statistical-analysis    # ç»Ÿè®¡åˆ†æ
      - sentiment-analysis      # æƒ…æ„Ÿåˆ†æ  
      - keyword-extraction      # å…³é”®è¯æå–
    parallelTimeoutMs: 30000
```

**èµ„æºç®¡ç†**ï¼š
```java
// åˆç†è®¾ç½®è¶…æ—¶å’Œèµ„æºé™åˆ¶
Map<String, Object> config = Map.of(
    "timeoutMs", 30000,           // 30ç§’è¶…æ—¶
    "maxIterations", 1000,        // æœ€å¤§1000æ¬¡è¿­ä»£
    "parallelTimeoutMs", 60000    // å¹¶è¡Œè¶…æ—¶60ç§’
);
```

### 4. ç›‘æ§å’Œè°ƒè¯•

**æ‰§è¡Œè·Ÿè¸ª**ï¼š
```java
// åœ¨å…³è”èŠ‚ç‚¹ä¸­æ·»åŠ è·Ÿè¸ªä¿¡æ¯
Map<String, Object> params = Map.of(
    "input_data", actualData,
    "_trace_id", "trace-" + UUID.randomUUID(),
    "_parent_workflow", mainWorkflow.getId(),
    "_execution_timestamp", System.currentTimeMillis()
);
```

**æ—¥å¿—è®°å½•**ï¼š
```yaml
# åœ¨æ¯ä¸ªå…³é”®å·¥ä½œæµä¸­æ·»åŠ æ—¥å¿—èŠ‚ç‚¹
- id: audit-log
  type: script
  name: æ‰§è¡Œå®¡è®¡
  config:
    script: |
      var auditInfo = {
        workflow_id: context.getWorkflowId(),
        execution_id: context.getExecutionId(),
        start_time: new Date().toISOString(),
        input_size: JSON.stringify(context.getData('input_data')).length
      };
      context.setData('audit_info', auditInfo);
      logger.info('å·¥ä½œæµæ‰§è¡Œå®¡è®¡: ' + JSON.stringify(auditInfo));
```

## ğŸ“ˆ æ€§èƒ½ç‰¹å¾

### æ‰§è¡Œæ¨¡å¼æ€§èƒ½å¯¹æ¯”

| æ‰§è¡Œæ¨¡å¼ | å»¶è¿Ÿ | ååé‡ | èµ„æºå ç”¨ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|---------|------|--------|----------|--------|----------|
| SYNC | é«˜ | ä½ | ä½ | ä½ | ä¸²è¡Œå¤„ç†ã€å¼ºä¾èµ– |
| ASYNC | ä½ | é«˜ | ä¸­ | ä¸­ | åå°ä»»åŠ¡ã€å¼±ä¾èµ– |
| CONDITIONAL | ä¸­ | ä¸­ | ä½ | ä¸­ | åˆ†æ”¯é€»è¾‘ã€æ¡ä»¶å¤„ç† |
| LOOP | é«˜ | ä¸­ | ä¸­ | ä¸­ | æ‰¹é‡å¤„ç†ã€ETL |
| PARALLEL | ä½ | æé«˜ | é«˜ | é«˜ | å¹¶è¡Œè®¡ç®—ã€ç‹¬ç«‹ä»»åŠ¡ |

### æœ€ä½³æ€§èƒ½å®è·µ

1. **é€‰æ‹©åˆé€‚çš„æ‰§è¡Œæ¨¡å¼**
   - æ•°æ®ä¾èµ–å¼º â†’ SYNC
   - ç‹¬ç«‹åå°ä»»åŠ¡ â†’ ASYNC  
   - æ¡ä»¶åˆ†æ”¯ â†’ CONDITIONAL
   - æ‰¹é‡å¤„ç† â†’ LOOP
   - å¹¶è¡Œè®¡ç®— â†’ PARALLEL

2. **ä¼˜åŒ–æ•°æ®ä¼ è¾“**
   - åªæ˜ å°„å¿…è¦çš„æ•°æ®å­—æ®µ
   - é¿å…ä¼ é€’å¤§å‹å¯¹è±¡
   - ä½¿ç”¨å¼•ç”¨è€Œéå¤åˆ¶

3. **åˆç†è®¾ç½®è¶…æ—¶**
   - æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾å®šåˆç†è¶…æ—¶
   - é¿å…è¿‡é•¿çš„é˜»å¡ç­‰å¾…
   - å®ç°è¶…æ—¶åçš„é™çº§å¤„ç†

## ğŸ”® æœªæ¥æ‰©å±•

### è®¡åˆ’ä¸­çš„åŠŸèƒ½

1. **åŠ¨æ€å·¥ä½œæµå‘ç°**
   - åŸºäºæ ‡ç­¾çš„å·¥ä½œæµæŸ¥æ‰¾
   - ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
   - è‡ªåŠ¨ä¾èµ–è§£æ

2. **é«˜çº§è°ƒåº¦ç­–ç•¥**
   - åŸºäºè´Ÿè½½çš„æ™ºèƒ½è°ƒåº¦
   - ä¼˜å…ˆçº§é˜Ÿåˆ—ç®¡ç†
   - èµ„æºé¢„ç•™æœºåˆ¶

3. **åˆ†å¸ƒå¼æ‰§è¡Œ**
   - è·¨èŠ‚ç‚¹å·¥ä½œæµæ‰§è¡Œ
   - è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
   - åˆ†å¸ƒå¼çŠ¶æ€ç®¡ç†

4. **å¯è§†åŒ–ç¼–æ’**
   - å›¾å½¢åŒ–å·¥ä½œæµè®¾è®¡å™¨
   - å®æ—¶æ‰§è¡Œç›‘æ§é¢æ¿
   - æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®

## ğŸ“š ç¤ºä¾‹é›†åˆ

### å…¸å‹ä¸šåŠ¡åœºæ™¯

1. **æ•°æ®å¤„ç†æµæ°´çº¿**
```yaml
# ETLæµæ°´çº¿ç¤ºä¾‹
workflow:
  id: etl-pipeline
  name: æ•°æ®ETLæµæ°´çº¿
  nodes:
    - id: extract
      type: reference
      config:
        executionMode: SYNC
        workflowId: data-extractor
        
    - id: transform  
      type: reference
      config:
        executionMode: SYNC
        workflowId: data-transformer
        inputMappings:
          extracted_data: raw_data
          
    - id: load
      type: reference
      config:
        executionMode: SYNC
        workflowId: data-loader
        inputMappings:
          transformed_data: clean_data
```

2. **å¾®æœåŠ¡ç¼–æ’**
```yaml
# å¾®æœåŠ¡åè°ƒç¤ºä¾‹
workflow:
  id: order-processing
  name: è®¢å•å¤„ç†æµç¨‹
  nodes:
    - id: validate-order
      type: reference
      config:
        executionMode: SYNC
        workflowId: order-validator
        
    - id: parallel-processing
      type: reference
      config:
        executionMode: PARALLEL
        workflowIds:
          - inventory-check
          - payment-processor  
          - shipping-calculator
          
    - id: order-confirmation
      type: reference
      config:
        executionMode: CONDITIONAL
        condition: "${all_services_success} == true"
        workflowId: order-confirmer
```

3. **AI/MLæµæ°´çº¿**
```yaml
# æœºå™¨å­¦ä¹ æµæ°´çº¿ç¤ºä¾‹  
workflow:
  id: ml-pipeline
  name: æœºå™¨å­¦ä¹ æµæ°´çº¿
  nodes:
    - id: data-preprocessing
      type: reference
      config:
        executionMode: SYNC
        workflowId: data-preprocessor
        
    - id: feature-engineering
      type: reference  
      config:
        executionMode: LOOP
        workflowId: feature-extractor
        loopDataKey: feature_groups
        
    - id: model-training
      type: reference
      config:
        executionMode: ASYNC
        workflowId: model-trainer
        waitForResult: true
        timeoutMs: 1800000  # 30åˆ†é’Ÿ
```

## ğŸ¯ æ€»ç»“

LogFlowçš„å…³è”èŠ‚ç‚¹åŠŸèƒ½æä¾›äº†å¼ºå¤§çš„**å·¥ä½œæµç¼–æ’å’Œå¤ç”¨èƒ½åŠ›**ï¼Œé€šè¿‡å¤šç§æ‰§è¡Œæ¨¡å¼å’Œçµæ´»çš„æ•°æ®æ˜ å°„æœºåˆ¶ï¼Œå¯ä»¥æ„å»ºä»ç®€å•åˆ°å¤æ‚çš„å„ç§ä¸šåŠ¡æµç¨‹ã€‚

### æ ¸å¿ƒä»·å€¼

1. **ğŸ“Š æå‡å¤ç”¨æ€§** - ä¸€æ¬¡å¼€å‘ï¼Œå¤šå¤„ä½¿ç”¨
2. **ğŸš€ å¢å¼ºçµæ´»æ€§** - å¤šç§æ‰§è¡Œæ¨¡å¼é€‚åº”ä¸åŒåœºæ™¯  
3. **âš¡ æ”¹å–„æ€§èƒ½** - å¹¶è¡Œå’Œå¼‚æ­¥æ‰§è¡Œæå‡æ•ˆç‡
4. **ğŸ¯ ç®€åŒ–ç®¡ç†** - ç»Ÿä¸€çš„æ³¨å†Œä¸­å¿ƒç®¡ç†æ‰€æœ‰å·¥ä½œæµ
5. **ğŸ›¡ï¸ ä¿è¯å¯é æ€§** - å®Œå–„çš„é”™è¯¯å¤„ç†å’Œç›‘æ§æœºåˆ¶

LogFlowå…³è”èŠ‚ç‚¹ä½¿å¤æ‚ä¸šåŠ¡æµç¨‹çš„æ„å»ºå˜å¾—**ç®€å•ã€é«˜æ•ˆã€å¯ç»´æŠ¤**ï¼Œæ˜¯ä¼ä¸šçº§å·¥ä½œæµç³»ç»Ÿçš„é‡è¦åŸºç¡€è®¾æ–½ã€‚
