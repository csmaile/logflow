# yaml-language-server: $schema=../schemas/logflow-workflow-schema.json
# 完整的Schema示例配置文件
# 展示LogFlow工作流配置的所有可能选项和最佳实践

workflow:
  id: "schema_example_workflow"
  name: "Schema示例工作流"
  description: "展示LogFlow YAML配置所有功能的完整示例工作流"
  version: "1.0.0"
  author: "LogFlow Development Team"
  metadata:
    category: "示例和教程"
    tags: ["示例", "教程", "完整配置"]
    complexity: "medium"
    created: "2024-01-20"
    documentation: "https://logflow.com/docs/examples"

# 全局配置 - 所有选项都是可选的
globalConfig:
  timeout: 60000                    # 工作流执行超时时间（毫秒）
  retryCount: 3                     # 节点失败重试次数
  logLevel: "INFO"                  # 日志级别: TRACE, DEBUG, INFO, WARN, ERROR
  enableMetrics: true               # 启用执行指标收集
  parallelExecution: true           # 启用并行执行
  maxConcurrentNodes: 4             # 最大并发节点数

# 节点定义 - 展示所有节点类型的配置
nodes:
  # 输入节点示例
  - id: "user_config"
    name: "用户配置输入"
    type: "input"
    position:
      x: 50
      y: 100
    config:
      inputs:
        - key: "user_settings"        # 从上下文获取数据的键
          alias: "userSettings"       # 在脚本中的别名
          required: true              # 是否必需
          dataType: "object"          # 数据类型: string, number, boolean, array, object
          defaultValue:               # 默认值（可选）
            enableDebug: false
            maxRecords: 1000
          description: "用户配置参数"  # 参数描述
      outputKey: "config"             # 输出到上下文的键

  # 数据源节点示例 - 模拟数据
  - id: "mock_data_source"
    name: "模拟日志数据源"
    type: "plugin"
    position:
      x: 50
      y: 200
    config:
      pluginType: "mock"             # 插件类型: mock, file
      mockType: "ARRAY"              # 模拟数据类型枚举值
      recordCount: 200               # 生成数据条数
      dataFormat: "JSON"             # 数据格式
      outputKey: "raw_logs"          # 输出键

  # 数据源节点示例 - 文件数据  
  - id: "file_data_source"
    name: "文件日志数据源"
    type: "plugin"
    position:
      x: 50
      y: 300
    config:
      pluginType: "file"             # 文件插件类型
      filePath: "/var/log/application.log"  # 文件路径
      format: "LINES"                # 数据格式枚举值
      encoding: "UTF-8"              # 字符编码
      maxLines: 5000                 # 最大读取行数
      outputKey: "file_logs"

  # 数据源节点示例 - 日志文件
  - id: "log_file_source"
    name: "日志文件数据源"  
    type: "plugin"
    position:
      x: 50
      y: 400
    config:
      pluginType: "file"             # 文件插件类型
      filePath: "/var/log/error.log" # 日志文件路径
      pattern: "ERROR"               # 过滤模式
      format: "LINES"                # 数据格式
      maxLines: 1000                 # 最大行数
      outputKey: "error_logs"

  # 脚本节点示例 - 数据预处理
  - id: "data_preprocessor"
    name: "数据预处理器"
    type: "script"
    position:
      x: 300
      y: 200
    config:
      scriptEngine: "javascript"     # 脚本引擎: javascript, groovy, python
      inputs:
        - key: "raw_logs"            # 输入数据键
          alias: "logs"              # 在脚本中的别名
          required: true             # 是否必需
          dataType: "array"          # 数据类型
          description: "原始日志数据"
        - key: "config"              # 配置数据
          alias: "config"
          required: false
          dataType: "object"
          defaultValue:
            minLevel: "INFO"
            excludeDebug: true
          description: "处理配置参数"
      outputKey: "filtered_logs"     # 输出数据键
      script: |                      # 多行脚本
        var config = typeof config !== 'undefined' ? config : {};
        var logs = typeof logs !== 'undefined' ? logs : [];
        var filtered = [];
        
        logger.info('开始预处理，输入数据条数: ' + logs.length);
        
        for (var i = 0; i < logs.length; i++) {
          var log = logs[i];
          
          // 根据配置过滤
          if (config.excludeDebug && log.level === 'DEBUG') {
            continue;
          }
          
          // 根据最小级别过滤
          if (config.minLevel) {
            var levels = ['TRACE', 'DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL'];
            var minIndex = levels.indexOf(config.minLevel);
            var logIndex = levels.indexOf(log.level);
            if (logIndex < minIndex) {
              continue;
            }
          }
          
          // 添加处理时间戳
          log.processedAt = utils.now();
          log.processedBy = 'data_preprocessor';
          
          filtered.push(log);
        }
        
        logger.info('预处理完成，输出数据条数: ' + filtered.length);
        
        // 统计信息可以通过输出结果传递
        var result = {
          data: filtered,
          stats: {
            inputCount: logs.length,
            outputCount: filtered.length,
            filterRate: ((logs.length - filtered.length) / logs.length * 100).toFixed(2) + '%'
          }
        };
        
        result;

  # 诊断节点示例 - 错误检测
  - id: "error_detector"
    name: "错误检测分析器"
    type: "diagnosis"
    position:
      x: 550
      y: 150
    config:
      diagnosisType: "error_detection"  # 诊断类型
      inputs:
        - key: "filtered_logs"         # 输入数据键
          alias: "logData"             # 脚本中的别名
          required: true               # 是否必需
          dataType: "array"            # 数据类型
          description: "过滤后的日志数据"
      outputKey: "error_results"       # 输出结果键
      errorPatterns:                   # 错误模式列表
        - "ERROR"
        - "FATAL"
        - "Exception"
        - "Failed"
        - "Timeout"

  # 诊断节点示例 - 性能分析
  - id: "performance_analyzer"
    name: "性能分析器"
    type: "diagnosis"
    position:
      x: 550
      y: 250
    config:
      diagnosisType: "performance_analysis"  # 性能分析
      inputs:
        - key: "filtered_logs"         # 输入数据键
          alias: "logData"             # 脚本中的别名
          required: true               # 是否必需
          dataType: "array"            # 数据类型
          description: "过滤后的日志数据"
      outputKey: "performance_results"
      slowThreshold: 1000.0            # 慢响应阈值（毫秒）

  # 诊断节点示例 - 模式分析
  - id: "pattern_analyzer"
    name: "模式分析器"
    type: "diagnosis"
    position:
      x: 550
      y: 350
    config:
      diagnosisType: "pattern_analysis"  # 模式分析
      inputs:
        - key: "filtered_logs"         # 输入数据键
          alias: "logData"             # 脚本中的别名
          required: true               # 是否必需
          dataType: "array"            # 数据类型
          description: "过滤后的日志数据"
      outputKey: "pattern_results"

  # 脚本节点示例 - 结果聚合
  - id: "result_aggregator"
    name: "结果聚合器"
    type: "script"
    position:
      x: 800
      y: 250
    config:
      scriptEngine: "javascript"
      inputs:
        - key: "error_results"         # 错误检测结果
          alias: "errorResults"
          required: true
          dataType: "object"
          description: "错误检测分析结果"
        - key: "performance_results"   # 性能分析结果
          alias: "performanceResults"
          required: true
          dataType: "object"
          description: "性能分析结果"
        - key: "pattern_results"       # 模式分析结果
          alias: "patternResults"
          required: true
          dataType: "object"
          description: "模式分析结果"
        - key: "preprocessing_stats"   # 预处理统计
          alias: "preprocessingStats"
          required: false
          defaultValue: {}
          dataType: "object"
          description: "数据预处理统计信息"
      mergeKey: "allResults"           # 合并后的键名
      outputKey: "final_report"
      script: |
        // 从合并的输入中获取所有结果
        var allResults = typeof allResults !== 'undefined' ? allResults : {};
        var errorResults = allResults.errorResults || {issueCount: 0, maxSeverity: 'LOW', issues: []};
        var performanceResults = allResults.performanceResults || {issueCount: 0, maxSeverity: 'LOW', issues: []};
        var patternResults = allResults.patternResults || {issueCount: 0, issues: []};
        var preprocessingStats = allResults.preprocessingStats || {};
        
        // 计算综合风险评分
        var riskScore = 0;
        if (errorResults.issueCount > 20) riskScore += 40;
        else if (errorResults.issueCount > 10) riskScore += 25;
        else if (errorResults.issueCount > 5) riskScore += 15;
        
        if (performanceResults.issueCount > 10) riskScore += 30;
        else if (performanceResults.issueCount > 5) riskScore += 20;
        
        // 确定风险级别
        var riskLevel = 'LOW';
        if (riskScore >= 60) riskLevel = 'CRITICAL';
        else if (riskScore >= 40) riskLevel = 'HIGH';
        else if (riskScore >= 20) riskLevel = 'MEDIUM';
        
        // 生成综合报告
        var report = {
          metadata: {
            generatedAt: utils.now(),
            workflowId: context.getWorkflowId(),
            executionId: context.getExecutionId()
          },
          summary: {
            riskScore: riskScore,
            riskLevel: riskLevel,
            totalIssues: errorResults.issueCount + performanceResults.issueCount + patternResults.issueCount,
            dataProcessing: preprocessingStats
          },
          details: {
            errors: {
              count: errorResults.issueCount,
              maxSeverity: errorResults.maxSeverity,
              issues: errorResults.issues.slice(0, 10)  // 只保留前10个
            },
            performance: {
              count: performanceResults.issueCount,
              maxSeverity: performanceResults.maxSeverity,
              issues: performanceResults.issues.slice(0, 5)
            },
            patterns: {
              count: patternResults.issueCount,
              findings: patternResults.issues.slice(0, 5)
            }
          },
          recommendations: []
        };
        
        // 生成建议
        if (riskLevel === 'CRITICAL') {
          report.recommendations.push('立即检查系统状态，存在严重问题');
        } else if (riskLevel === 'HIGH') {
          report.recommendations.push('建议尽快处理发现的问题');
        } else if (riskLevel === 'MEDIUM') {
          report.recommendations.push('关注发现的问题，建议定期检查');
        } else {
          report.recommendations.push('系统运行正常，保持监控');
        }
        
        if (errorResults.issueCount > 15) {
          report.recommendations.push('错误数量较多，建议检查错误日志');
        }
        
        if (performanceResults.issueCount > 8) {
          report.recommendations.push('发现性能问题，建议优化响应时间');
        }
        
        logger.info('生成综合报告: 风险级别=' + riskLevel + ', 总问题=' + report.summary.totalIssues);
        report;

  # 通知节点示例 - JSON文件输出
  - id: "json_report_output"
    name: "JSON报告输出"
    type: "notification"
    position:
      x: 1050
      y: 200
    config:
      providerType: "file"            # 通知提供者类型
      inputs:
        - key: "final_report"         # 输入数据键
          alias: "report"             # 脚本中的别名
          required: true              # 是否必需
          dataType: "object"          # 数据类型
          description: "最终分析报告"
      title: "综合日志分析报告"       # 通知标题
      messageType: "JSON"            # 消息类型
      priority: "NORMAL"             # 优先级
      provider:
        filePath: "reports/comprehensive_analysis.json"  # 文件路径
        format: "json"               # 文件格式

  # 通知节点示例 - 控制台输出
  - id: "console_summary"
    name: "控制台摘要输出"
    type: "notification"
    position:
      x: 1050
      y: 300
    config:
      providerType: "console"         # 控制台通知提供者
      inputs:
        - key: "final_report"         # 输入数据键
          alias: "report"             # 脚本中的别名
          required: true              # 是否必需
          dataType: "object"          # 数据类型
          description: "最终分析报告"
      title: "日志分析摘要"           # 通知标题
      messageType: "TEXT"            # 消息类型
      priority: "HIGH"               # 优先级
      provider:
        format: "detailed"           # 输出格式
        timestamp: true              # 包含时间戳

  # 通知节点示例 - 上下文输出
  - id: "context_output"
    name: "上下文数据输出"
    type: "notification"
    position:
      x: 1050
      y: 400
    config:
      providerType: "context"         # 上下文通知提供者
      inputs:
        - key: "final_report"         # 输入数据键
          alias: "report"             # 脚本中的别名
          required: true              # 是否必需
          dataType: "object"          # 数据类型
          description: "最终分析报告"
      title: "工作流执行结果"         # 通知标题
      messageType: "JSON"            # 消息类型
      priority: "NORMAL"             # 优先级
      provider:
        contextKey: "workflow_result" # 上下文键名

# 连接关系定义
connections:
  # 配置输入到数据预处理
  - from: "user_config"
    to: "data_preprocessor"
    enabled: true

  # 数据源到预处理（只有启用的数据源会连接）
  - from: "mock_data_source"
    to: "data_preprocessor"
    enabled: true

  # 可选的文件数据源连接（已禁用）
  - from: "file_data_source"
    to: "data_preprocessor"
    enabled: false

  # 预处理到各个分析器
  - from: "data_preprocessor"
    to: "error_detector"
    enabled: true

  - from: "data_preprocessor"
    to: "performance_analyzer"
    enabled: true

  - from: "data_preprocessor"
    to: "pattern_analyzer"
    enabled: true

  # 所有分析器到结果聚合器
  - from: "error_detector"
    to: "result_aggregator"
    enabled: true

  - from: "performance_analyzer"
    to: "result_aggregator"
    enabled: true

  - from: "pattern_analyzer"
    to: "result_aggregator"
    enabled: true

  # 聚合结果到各个输出
  - from: "result_aggregator"
    to: "json_report_output"
    enabled: true

  - from: "result_aggregator"
    to: "console_summary"
    enabled: true

  - from: "result_aggregator"
    to: "context_output"
    enabled: true
